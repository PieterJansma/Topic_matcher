# Topic_matcher

# GECKO Variable Mapping Experiments

This repository contains experiments for **mapping variable names** to **topics** also exploring existing **Gecko Ontology**, exploring how different text enrichment and embedding strategies affect performance.

We experiment with:
- raw labeled data,
- LLM-enriched definitions and synonyms,
- GECKO ontology true-matches,
- different embedding models (general vs. biomedical),
- and longer enriched definitions.

---

## üìÇ Data Files

### 1. `Labeled_variables.xlsx`
- **Description**: Manually labeled dataset of variables with their parent categories.  
- **Columns**:  
  - `name`: variable name (e.g., *Pregnancy number*).  
  - `parent`: manually assigned parent category.  
  - `definition`: optional short definition (often missing or short).  

**Example:**
| name              | parent              | definition |
|-------------------|---------------------|------------|
| Pregnancy number  | Identifiers         | Pregnancy number      |
| Food groups (M)   | 	Nutrition | Vegetables without potatoes  during pregnancy,Fruits during pregnancy. etcc|
| Suprailiac skinfold   | Suprailiac skinfold | NaN |


---

### 2. `Labeled_variables_with_llm_enrichment.csv`
- **Description**: Same as above, but with **LLM-enriched fields**.  
- **Columns added**:  
  - `definition_enriched`: one-sentence enriched definition generated by LLM.  
  - `synonyms_enriched`: Did not work will be looking into this.  
  - `definition_source`: `llm_generated` or `original`.  
  - `gen_sim_name_def`: cosine similarity between term and definition (quality gate).  

**Example:**
| name              | parent            | definition_enriched                                           | synonyms_enriched                  |
|-------------------|-------------------|---------------------------------------------------------------|------------------------------------|
| Pregnancy number  | Identifiers | Pregnancy number is an information content entity that is the outcome of a dubbing process and is used to refer to one instance of entity shared by a group of people to refer to that individual entity             | pregnancy count, gravidity         |
| Food groups (M)   | 	Nutrition | Nutritional history is a lifestyle history that is about the diet and nutrition of an individual       | dietary categories, nutrition sets |

---

### 3. `parent_gecko_candidates_top5.xlsx`
- **Description**: Top-5 candidate GECKO ontology classes per parent (based on embedding similarity).  
- **Columns**:  
  - `parent`, `parent_definition`, `gecko_label`, `gecko_definition`, `sim` (cosine similarity), `auto_suggest`.  
  - `approved`: manual selection (`TRUE` if correct match).  

**Example:**
| parent              | gecko_label     | gecko_definition                            | sim  | approved |
|---------------------|-----------------|---------------------------------------------|------|----------|
| Pregnancy history   | Gravidity       | *The number of times a female has been pregnant.* | 0.87 | TRUE     |
| Diet during pregnancy | Food intake   | *The consumption of food and drink by an organism.* | 0.82 | TRUE |

---

---

## üß™ Experimental Strategies

We evaluated progressively richer strategies for text representation:

1. **Baseline (No enrichment)**  
   - Input = `name` only, or `name + original definition` (when available).  
   - Model: `all-MiniLM-L6-v2` baseline.  

2. **LLM Enrichment**  
   - Input = `name + definition_enriched` (LLM-generated).  
   - Synonyms included where available.  
   - Model: general semantic search models like `multi-qa-mpnet-base-dot-v1`.  

3. **LLM + GECKO Mapping**  
   - Add GECKO label/definition for parents (based on manual `TRUE` matches).  
   - Training embeddings use GECKO; query embeddings may exclude it (to simulate real-world usage).  

4. **Extended Definitions (Longer LLM enrichment)**  
   - LLM prompted to generate longer, more detailed definitions.  
   - Idea: give embedding models more semantic signal.  

---

## üî¨ Models Evaluated

We compared multiple embedding models:

### General-purpose Language Models
- `thenlper/gte-large`
- `multi-qa-mpnet-base-dot-v1`
- `sentence-t5-base`

### Biomedical / Domain Models
- `allenai/specter`
- `biobert-base-cased-v1.1`
- (optional future: `microsoft/BiomedNLP-PubMedBERT`)

---

## üìä Results

### LOOCV Accuracy (Top-1 / Top-3)

| Strategy                    | Model                     | Top-1  | Top-3  | Notes |
|------------------------------|---------------------------|--------|--------|-------|
| Baseline (no enrichment)     | all-MiniLM-L6-v2          | 0.xxx  | 0.xxx  | Short input only |
| LLM Enrichment               | multi-qa-mpnet-base-dot-v1| 0.720  | 0.861  | Big boost with enriched defs |
| LLM Enrichment               | sentence-t5-base          | 0.718  | 0.857  | Similar to mpnet |
| LLM + GECKO (query=with GECKO) | thenlper/gte-large      | 0.774  | 0.896  | Best so far |
| LLM + GECKO (query=no GECKO) | thenlper/gte-large        | 0.769  | 0.886  | Robust even w/out GECKO |

üëâ **Takeaway:**  
- Enrichment consistently improves accuracy.  
- GECKO adds further boost, but results hold up even when GECKO isn‚Äôt available at query time.  

---

## üìâ Error Analysis

- **Confusions** often occur between semantically close parents (e.g., *Pregnancy history* vs. *Pregnancy outcomes*).  
- **Synonyms help** disambiguate similar categories.  
- **GECKO helps** by aligning with ontology structure.  

Future work:  
- per-parent accuracy tables,  
- confusion matrix visualization.  

---

## ‚öôÔ∏è Reproducing the Results

1. **Enrich definitions & synonyms**
   ```bash
   python enrich_llm_defs.py
